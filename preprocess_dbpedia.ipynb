{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlDHfWAaU98q"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "HqNQQdwbIVGF",
    "outputId": "25bd16fd-7053-4187-c22e-1300c4b4913a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>E. D. Abbott Ltd</td>\n",
       "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Schwan-Stabilo</td>\n",
       "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Q-workshop</td>\n",
       "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Marvell Software Solutions Israel</td>\n",
       "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Bergan Mercy Medical Center</td>\n",
       "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  ...                                               text\n",
       "0      1  ...   Abbott of Farnham E D Abbott Limited was a Br...\n",
       "1      1  ...   Schwan-STABILO is a German maker of pens for ...\n",
       "2      1  ...   Q-workshop is a Polish company located in Poz...\n",
       "3      1  ...   Marvell Software Solutions Israel known as RA...\n",
       "4      1  ...   Bergan Mercy Medical Center is a hospital loc...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(560000, 3)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TY KU</td>\n",
       "      <td>TY KU /taɪkuː/ is an American alcoholic bever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Odd Lot Entertainment</td>\n",
       "      <td>OddLot Entertainment founded in 2001 by longt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Henkel</td>\n",
       "      <td>Henkel AG &amp; Company KGaA operates worldwide w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GOAT Store</td>\n",
       "      <td>The GOAT Store (Games Of All Type Store) LLC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RagWing Aircraft Designs</td>\n",
       "      <td>RagWing Aircraft Designs (also called the Rag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  ...                                               text\n",
       "0      1  ...   TY KU /taɪkuː/ is an American alcoholic bever...\n",
       "1      1  ...   OddLot Entertainment founded in 2001 by longt...\n",
       "2      1  ...   Henkel AG & Company KGaA operates worldwide w...\n",
       "3      1  ...   The GOAT Store (Games Of All Type Store) LLC ...\n",
       "4      1  ...   RagWing Aircraft Designs (also called the Rag...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(70000, 3)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DBPEDIA_DIR = 'data/dbpedia_csv'\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "train_data_path = os.path.join(DBPEDIA_DIR, 'train.csv')\n",
    "test_data_path = os.path.join(DBPEDIA_DIR, 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_data_path, header=None, names=['class', 'title', 'text'])\n",
    "display(train_df.head())\n",
    "display(train_df.shape)\n",
    "test_df = pd.read_csv(test_data_path, header=None, names=['class', 'title', 'text'])\n",
    "display(test_df.head())\n",
    "display(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JvTcowXVCo7"
   },
   "source": [
    "## Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u63DCDBhI7ZT",
    "outputId": "bef36b6d-a6ef-4367-ec37-25b0f00b6891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MTON9sDqJFou",
    "outputId": "c19a2d1a-1a3c-4376-ed75-35fa3486f4f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TY KU</td>\n",
       "      <td>TY KU /taɪkuː/ is an American alcoholic bever...</td>\n",
       "      <td>[taɪkuː, american, alcoholic, beverage, compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Odd Lot Entertainment</td>\n",
       "      <td>OddLot Entertainment founded in 2001 by longt...</td>\n",
       "      <td>[oddlot, entertainment, found, longtime, produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Henkel</td>\n",
       "      <td>Henkel AG &amp; Company KGaA operates worldwide w...</td>\n",
       "      <td>[henkel, company, kgaa, operate, worldwide, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GOAT Store</td>\n",
       "      <td>The GOAT Store (Games Of All Type Store) LLC ...</td>\n",
       "      <td>[goat, store, game, type, store, llc, one, lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RagWing Aircraft Designs</td>\n",
       "      <td>RagWing Aircraft Designs (also called the Rag...</td>\n",
       "      <td>[ragwing, aircraft, design, also, call, ragwin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  ...                                    preprocess_text\n",
       "0      1  ...  [taɪkuː, american, alcoholic, beverage, compan...\n",
       "1      1  ...  [oddlot, entertainment, found, longtime, produ...\n",
       "2      1  ...  [henkel, company, kgaa, operate, worldwide, le...\n",
       "3      1  ...  [goat, store, game, type, store, llc, one, lar...\n",
       "4      1  ...  [ragwing, aircraft, design, also, call, ragwin...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "def preprocess_text(text):\n",
    "    # removing numbers\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    \n",
    "    # removing urls\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # removing punctuation and special characters\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # convert to lowercase and lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(token.lower(), pos='v') for token in tokens]\n",
    "    \n",
    "    # remove stop words\n",
    "    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n",
    "    \n",
    "    # remove small words\n",
    "    keywords = [word for word in keywords if len(word) > 2]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "train_df['preprocess_text'] = train_df.text.apply(preprocess_text)\n",
    "test_df['preprocess_text'] = test_df.text.apply(preprocess_text)\n",
    "train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX2Kc31kVMt2"
   },
   "source": [
    "## Generating word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RPLEKlJJIVA",
    "outputId": "f970a1b1-99e6-4392-c52d-655fad9a9b29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672056, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "all_text = pd.concat([train_df.preprocess_text, test_df.preprocess_text], axis=0)\n",
    "w2v_model = Word2Vec(sentences=all_text, size=300, min_count=1, window=5, workers=4, sg=1)\n",
    "w2v_model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vzRVRvlmgsA"
   },
   "source": [
    "Saving the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqpZpMZxJXNu"
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.save(os.path.join(DATA_DIR, 'dbpedia.wordembeddings'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIKufmOtmvjJ"
   },
   "source": [
    "## Generating word vectors for text\n",
    "Loading word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "fUFOYve9V0LE",
    "outputId": "2ee20357-11d3-4ee5-926d-e5393e14b5b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_vec</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.14539934198974686, 0.12077933725188761, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.17643223330378532, 0.046283949711700766, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.12377960653975606, 0.0881067788771664, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.05970577464904636, 0.13701889221556485, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.09968144951486274, -0.015847527912180675, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>[[0.21751869964240075, 0.11445621912757498, -0...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>[[0.08986973749207598, -0.03564547627632107, -...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>[[0.2279204372316599, -0.09692106769320422, 0....</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>[[0.1286562429741025, 0.03627264947863296, -0....</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>[[0.19977391041307288, -0.06254904719770077, 0...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_vec  class\n",
       "0      [[0.14539934198974686, 0.12077933725188761, -0...      1\n",
       "1      [[0.17643223330378532, 0.046283949711700766, -...      1\n",
       "2      [[0.12377960653975606, 0.0881067788771664, -0....      1\n",
       "3      [[0.05970577464904636, 0.13701889221556485, -0...      1\n",
       "4      [[0.09968144951486274, -0.015847527912180675, ...      1\n",
       "...                                                  ...    ...\n",
       "69995  [[0.21751869964240075, 0.11445621912757498, -0...     14\n",
       "69996  [[0.08986973749207598, -0.03564547627632107, -...     14\n",
       "69997  [[0.2279204372316599, -0.09692106769320422, 0....     14\n",
       "69998  [[0.1286562429741025, 0.03627264947863296, -0....     14\n",
       "69999  [[0.19977391041307288, -0.06254904719770077, 0...     14\n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load(os.path.join(DATA_DIR, 'dbpedia.wordembeddings'), mmap='r')\n",
    "\n",
    "def vectorize_text(text, wv):\n",
    "    \"\"\"\n",
    "    Function to vectorize text by averaging the word vectors \n",
    "    for each word in the text\n",
    "    \"\"\"\n",
    "    vec = np.zeros((1, 300))\n",
    "    for w in text:\n",
    "        vec += wv.get_vector(w)\n",
    "\n",
    "    return vec / len(text)\n",
    "\n",
    "train_df['text_vec'] = train_df.preprocess_text.apply(vectorize_text, args=(word_vectors,))\n",
    "test_df['text_vec'] = test_df.preprocess_text.apply(vectorize_text, args=(word_vectors,)) \n",
    "\n",
    "test_df[['text_vec', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6OkTTtHY9U6",
    "outputId": "6d71c391-7e54-436c-b83a-e15212fa4b4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [[0.14539934198974686, 0.12077933725188761, -0...\n",
       "1        [[0.17643223330378532, 0.046283949711700766, -...\n",
       "2        [[0.12377960653975606, 0.0881067788771664, -0....\n",
       "3        [[0.05970577464904636, 0.13701889221556485, -0...\n",
       "4        [[0.09968144951486274, -0.015847527912180675, ...\n",
       "                               ...                        \n",
       "69995    [[0.21751869964240075, 0.11445621912757498, -0...\n",
       "69996    [[0.08986973749207598, -0.03564547627632107, -...\n",
       "69997    [[0.2279204372316599, -0.09692106769320422, 0....\n",
       "69998    [[0.1286562429741025, 0.03627264947863296, -0....\n",
       "69999    [[0.19977391041307288, -0.06254904719770077, 0...\n",
       "Name: text_vec, Length: 70000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KvltynFAn03a"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_df.text_vec).to_pickle(os.path.join(DATA_DIR, 'dbpedia_train_all_x.pkl'))\n",
    "pd.DataFrame(train_df['class']).to_pickle(os.path.join(DATA_DIR, 'dbpedia_train_all_y.pkl'))\n",
    "pd.DataFrame(test_df.text_vec).to_pickle(os.path.join(DATA_DIR, 'dbpedia_test_wv.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDDhr8Npq3CD"
   },
   "source": [
    "## Generating label splits\n",
    "We're generating multiple datasets with different proportions of the training data that is labelled and unlabelled. We will be using these splits to benchmark the performance of our sem-supervised learning model:\n",
    "* Label Split 1: 2000 data pts / class (5% of dataset)\n",
    "* Label Split 2: 500 data pts / class (1.25% dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "354D-eP0Yvr8"
   },
   "outputs": [],
   "source": [
    "# reading data from pkl binary files\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'dbpedia_train_wv.pkl'), 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "Ah10rm15n4XT",
    "outputId": "6624a060-f817-4307-8524-13d491a2e5b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40000., 40000., 40000., 40000., 40000., 40000., 40000., 40000.,\n",
       "        40000., 40000., 40000., 40000., 80000.]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " <a list of 13 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = np.unique(train_df['class'])\n",
    "plt.hist(train_df['class'], bins=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fIqoY4Dmrqg8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_label_splits():\n",
    "    \"\"\"\n",
    "    Function to generate the label splits\n",
    "    \"\"\"\n",
    "    num_per_class_label_split1 = 2000\n",
    "    num_per_class_label_split2 = 500\n",
    "\n",
    "    # final dataframes\n",
    "    x_split1_df, y_split1_df = pd.DataFrame(columns=['text_vec']), pd.DataFrame(columns=['class'])\n",
    "    x_split2_df, y_split2_df = pd.DataFrame(columns=['text_vec']), pd.DataFrame(columns=['class'])\n",
    "\n",
    "    for c in classes:\n",
    "        c_idx = np.where(train_df['class'] == c)[0]\n",
    "        # generating split 1\n",
    "        split1_idx = random.sample(c_idx.tolist(), num_per_class_label_split1)\n",
    "        x_split1_df = x_split1_df.append(train_df['text_vec'].iloc[split1_idx])\n",
    "        y_split1_df = y_split1_df.append(train_df['text_vec'].iloc[split1_idx])\n",
    "        # generating split 2\n",
    "        split2_idx = random.sample(c_idx.tolist(), num_per_class_label_split2)\n",
    "        x_split2_df = x_split2_df.append(train_df['text_vec'].iloc[split2_idx])\n",
    "        y_split2_df = y_split2_df.append(train_df['text_vec'].iloc[split2_idx])\n",
    "\n",
    "    x_split1_df.to_pickle(os.path.join(DATA_DIR, 'dbpedia_train_x_split1.pkl'))\n",
    "    y_split1_df.to_pickle(os.path.join(DATA_DIR, 'dbpedia_train_y_split1.pkl'))\n",
    "    x_split2_df.to_pickle(os.path.join(DATA_DIR, 'dbpedia_train_x_split2.pkl'))\n",
    "    y_split2_df.to_pickle(os.path.join(DATA_DIR, 'dbpedia_train_y_split2.pkl'))\n",
    "\n",
    "generate_label_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0l87jlA2TJ1E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "preprocess_dbpedia.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
